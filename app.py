# app.py
# ============================================================
# Streamlit HUB (app principale)
# - Point d'entrÃ©e pour Streamlit.io
# - Affiche un menu latÃ©ral (Ã©tude de marchÃ© / site dÃ©mo)
# - Appelle des modules sÃ©parÃ©s dans src/
#
# IMPORTANT :
# - Ne lance PAS les scripts offline (traitement_db.py / build_ml_ready.py)
# - L'app consomme uniquement les CSV dÃ©jÃ  prÃ©sents dans data/
# ============================================================

import streamlit as st


# -----------------------------
# Config Streamlit
# -----------------------------
st.set_page_config(
    page_title="Projet 2 â€” CinÃ©ma Creuse",
    layout="wide",
)

# -----------------------------
# Imports des pages (modules)
# -----------------------------
# NOTE : Ces fichiers doivent exister dans src/
# - src/market_app.py  -> render_market()
# - src/site_app.py    -> render_site()
#
# Pour l'instant, si tu n'as pas encore crÃ©Ã© ces modules,
# tu peux laisser les imports commentÃ©s et utiliser les placeholders plus bas.
try:
    from src.market_app import render_market
except Exception:
    render_market = None

try:
    from src.site_app import render_site
except Exception:
    render_site = None


# -----------------------------
# UI â€” Sidebar
# -----------------------------
st.sidebar.title("Projet 2 â€” Hub")

section = st.sidebar.radio(
    "Navigation",
    [
        "Ã‰tude de marchÃ©",
        "Site (dÃ©mo + reco)",
        "DB / Notes",
    ],
    index=0,
)

st.sidebar.markdown("---")

# Optionnel : petit indicateur de statut
st.sidebar.caption("DonnÃ©es ML : data/imdb/out/ml_ready/")
st.sidebar.caption("DonnÃ©es marchÃ© : data/INSEE/ + data/CNC/")


# -----------------------------
# Contenu principal
# -----------------------------
if section == "Ã‰tude de marchÃ©":
    st.title("Ã‰tude de marchÃ© â€” Creuse")
    st.caption("Visualisations INSEE + CNC (module sÃ©parÃ©).")

    if render_market is None:
        st.warning(
            "Module `src/market_app.py` introuvable ou en erreur.\n\n"
            "CrÃ©e `src/market_app.py` avec une fonction `render_market()`."
        )
        st.code(
            "def render_market():\n"
            "    import streamlit as st\n"
            "    st.write('Market app placeholder')\n",
            language="python",
        )
    else:
        render_market()

elif section == "Site (dÃ©mo + reco)":
    st.title("Site â€” DÃ©mo + Recommandations")
    st.caption("Recherche film/personne + recommandations + page film (module sÃ©parÃ©).")

    if render_site is None:
        st.warning(
            "Module `src/site_app.py` introuvable ou en erreur.\n\n"
            "CrÃ©e `src/site_app.py` avec une fonction `render_site()`."
        )
        st.code(
            "def render_site():\n"
            "    import streamlit as st\n"
            "    st.write('Site app placeholder')\n",
            language="python",
        )
    else:
        render_site()

else:  # "DB / Notes"
    st.title("DB / Notes")

    st.info(
                """
            ## Documentation du pipeline (IMDb â†’ parts â†’ ML-ready â†’ app Streamlit)

            Cette section documente **ce que fait chaque fichier**, **pourquoi il existe**, et **comment fonctionne le systÃ¨me de recommandation**.
            Lâ€™objectif est dâ€™avoir un dÃ©pÃ´t **reproductible** : tu peux reconstruire les CSV *ML-ready* Ã  partir des sources IMDb/TMDB, puis dÃ©ployer lâ€™app sur **Streamlit Community Cloud** (streamlit.io) sans exÃ©cuter les scripts offline.

            ---

            # 1) Structure du projet

            ```
            projet_2_final/
            â”œâ”€â”€ app.py                      # HUB Streamlit (point dâ€™entrÃ©e streamlit.io)
            â”œâ”€â”€ src/
            â”‚   â”œâ”€â”€ market_app.py           # Ã©tude de marchÃ© (INSEE/CNC)
            â”‚   â”œâ”€â”€ site_app.py             # site dÃ©mo + recherche + reco
            â”‚   â”œâ”€â”€ ml_data.py              # charge les CSV (parts) et renvoie films/persons
            â”‚   â”œâ”€â”€ reco_engine.py          # ranking homepage + recommender KNN (cosine)
            â”‚   â””â”€â”€ tmdb_cache.py           # appels TMDB + cache CSV + candidate set
            â”‚
            â””â”€â”€ data/
                â”œâ”€â”€ INSEE/                  # csv marchÃ©
                â”œâ”€â”€ CNC/                    # csv marchÃ©
                â””â”€â”€ imdb/
                    â””â”€â”€ out/
                        â”œâ”€â”€ films/          # part_*.csv (100k films filtrÃ©s)
                        â”œâ”€â”€ credits/        # part_*.csv (crÃ©dits filtrÃ©s)
                        â””â”€â”€ ml_ready/
                            â”œâ”€â”€ films_ml/   # part_*.csv (enrichi pour ML)
                            â”œâ”€â”€ person_index.csv
                            â””â”€â”€ tmdb_cache.csv
            ```

            **IdÃ©e clÃ© :**
            - Les gros fichiers IMDb sont **dÃ©coupÃ©s en parts** pour rester < 100MB sur GitHub.
            - Lâ€™app Streamlit **ne fait que lire** ces parts et construire le modÃ¨le en mÃ©moire (avec cache).
            - Les scripts `traitement_db.py` et `build_ml_ready.py` sont **offline** (local) et servent Ã  gÃ©nÃ©rer les CSV versionnÃ©s.

            ---

            # 2) Fichiers OFFLINE (dans `data/imdb/`)

            Ces scripts se lancent en local (VS Code).  
            Ils ne doivent pas tourner sur Streamlit.io (trop lourd, trop lent, et nÃ©cessite des tÃ©lÃ©chargements).

            ## 2.1 `data/imdb/traitement_db.py`
            **RÃ´le :** tÃ©lÃ©charger/filtrer IMDb (TSV.gz) + fusion avec un export TMDB (csv) puis produire :
            - `data/imdb/out/films/part_*.csv`
            - `data/imdb/out/credits/part_*.csv`

            ### Pourquoi ce fichier existe ?
            IMDb est Ã©norme. Tu ne peux pas pousser les TSV bruts sur GitHub, ni les charger sur Streamlit.io.  
            Donc tu fais un **filtrage dur** (ex: films depuis 1980, min votes, top 100k) et tu sors des CSV â€œpropresâ€.

            ### Filtres appliquÃ©s (config)
            - `MIN_YEAR = 1980`
            - `MIN_VOTES = 300`
            - `TOP_N_FILMS = 100_000` (classÃ©s par `numVotes`)

            ### Output â€œfilmsâ€ (1 ligne = 1 film)
            Colonnes principales (selon ton script) :
            - `tconst`, `primaryTitle`, `startYear`, `genres`, `runtimeMinutes`, `averageRating`, `numVotes`,
            - `directors`, `writers`,
            - + champs TMDB (budget, revenue, poster_path, overview, popularity, vote_average, vote_count, etc.)

            ### Output â€œcreditsâ€ (1 ligne = 1 personne x film)
            Colonnes principales :
            - `tconst`, `nconst`, `category`, `characters`, `primaryName`, `birthYear`, `primaryProfession`, etc.

            ### Fonctions utilitaires
            - `clear_dir(folder)` : supprime les anciens `part_*.csv`
            - `write_parts_from_df(df, out_dir, part_rows)` : dÃ©coupe un DF en plusieurs `part_XXX.csv`
            - `write_chunked_parts(...)` : writer incrÃ©mental (utile pour `credits` afin dâ€™Ã©viter lâ€™explosion RAM)

            ---

            ## 2.2 `data/imdb/build_ml_ready.py`
            **RÃ´le :** transformer tes parts â€œfilms + creditsâ€ en tables plus adaptÃ©es au ML et Ã  lâ€™UI :
            - `data/imdb/out/ml_ready/films_ml/part_*.csv`
            - `data/imdb/out/ml_ready/person_index.csv`

            ### Pourquoi tu as besoin dâ€™un â€œml_readyâ€ ?
            Le fichier `credits` contient plusieurs lignes par film, donc pas pratique pour :
            - afficher vite â€œRÃ©alisateur / casting principalâ€ sur la page film,
            - crÃ©er un modÃ¨le de similaritÃ© â€œfilm â†” filmâ€ (il faut 1 ligne par film + features texte)

            ### Ce que construit `build_ml_ready.py`

            #### A) `films_ml`
            Câ€™est `films` + agrÃ©gations dÃ©rivÃ©es de `credits` :
            - `director_name` : nom du rÃ©alisateur (rows `category == 'director'`)
            - `cast_top` : top acteurs/actrices (ex: 5 premiers) concatÃ©nÃ©s en string
            - `soup` : â€œtexte combinÃ©â€ utilisÃ© pour le TFâ€‘IDF (voir reco_engine)

            #### B) `person_index.csv`
            Index â€œpersonne â†’ filmsâ€ pour la recherche acteur :
            - une ligne par `nconst` avec :
            - `primaryName`
            - `known_for_tconst` (liste/texte de tconst associÃ©s)

            ### Fonctions principales
            - `list_parts(dir)` : liste les `part_*.csv`
            - `load_films()` : concat les parts films
            - `build_cast_and_director_and_person_index(...)` :
            - lit credits
            - calcule `director_name`, `cast_top`
            - construit `person_index`
            - `write_parts_from_df(...)` : Ã©crit `films_ml` en parts

            ---

            # 3) Fichiers APP (dans `src/`) â€” utilisÃ©s sur Streamlit.io

            ## 3.1 `src/ml_data.py`
            **RÃ´le :** charger des CSV dÃ©coupÃ©s (`part_*.csv`) depuis `data/` (local repo ou raw GitHub).

            ### Fonctions
            - `_load_csv_parts(folder_or_base_url, pattern='part_*.csv')` : lit toutes les parts et concat
            - `load_films_ml(base)` : charge `data/imdb/out/ml_ready/films_ml/part_*.csv`
            - `load_person_index(base)` : charge `person_index.csv` (**doit contenir `nconst`**)
            - `load_ml_data(base)` : renvoie `(films_ml, persons_index)`

            **Pourquoi ce fichier est important ?**
            - Streamlit.io charge tout depuis le repo : il faut un loader robuste, â€œparts-friendlyâ€.
            - `@st.cache_data` (dans les modules appelants) Ã©vite de recharger/concat Ã  chaque interaction.

            ---

            ## 3.2 `src/reco_engine.py`
            **RÃ´le :** toute la logique de recommandation.

            Tu as 2 mÃ©canismes complÃ©mentaires :

            ### (1) Homepage â€œTop par genreâ€ (ranking)
            But : afficher un Top N stable et rapide, sans modÃ¨le complexe.

            - `compute_rank_score(...)` calcule un score avec :
            - popularitÃ© (TMDB `popularity`)
            - qualitÃ© (notes `vote_average` / `averageRating`)
            - crÃ©dibilitÃ© (volumes `vote_count` / `numVotes`)
            - `top_by_genre(films, genre, n=10)` : filtre `genres` puis trie par `rank_score`

            **Pourquoi câ€™est adaptÃ© Ã  la homepage ?**
            - robuste (pas besoin dâ€™entraÃ®nement),
            - rÃ©sultat cohÃ©rent mÃªme sans interaction.

            ### (2) Reco â€œquand tu cherches un filmâ€ (KNN content-based)
            But : si lâ€™utilisateur sÃ©lectionne un film, proposer des films similaires.

            #### Feature principale : un texte â€œsoupâ€
            `build_soup_row(row)` assemble un texte Ã  partir de colonnes disponibles :
            - `primaryTitle` / `originalTitle`
            - `genres`
            - `director_name`
            - `cast_top`
            - (optionnel) `original_language`, `startYear`

            Ensuite :
            - TFâ€‘IDF (texte â†’ vecteurs)
            - SimilaritÃ© cosine (top voisins)

            Classe :
            - `ContentKNNRecommender`
            - `fit(films_ml)` construit TFâ€‘IDF + matrice
            - `recommend_by_tconst(tconst, top_n)` renvoie les films les plus similaires

            #### Recherche acteur
            - `search_person_names(person_index, query)` : recherche
            - `recommend_from_person(...)` : rÃ©cupÃ¨re les films liÃ©s Ã  lâ€™acteur puis propose autour.

            ---

            ## 3.3 `src/tmdb_cache.py`
            **RÃ´le :** intÃ©grer TMDB *sans casser le modÃ¨le local*.

            Deux usages :

            ### A) â€œCandidate setâ€ (films en cours / Ã  venir)
            - `build_candidate_tconst_set(...)` :
            - appelle TMDB (rÃ©gion FR, langue fr-FR)
            - rÃ©cupÃ¨re `now_playing` / `upcoming`
            - convertit TMDB â†’ `imdb_id` (tconst)
            - intersecte avec ta DB locale â†’ `candidate_set`

            ### B) Fallback â€œhors DB localeâ€
            Si un film nâ€™existe pas en local :
            - `tmdb_search_movie(query)`
            - `tmdb_movie_details(tmdb_id)`
            - `tmdb_movie_recommendations(tmdb_id)`
            - `tmdb_results_to_tconst_list(results)`
            - `tmdb_overview_from_tconst(tconst)`

            ### Cache CSV
            `tmdb_cache.csv` Ã©vite de re-taper TMDB Ã  chaque refresh (quotas + perf).

            ---

            ## 3.4 `src/site_app.py`
            **RÃ´le :** UI du â€œNetflix-likeâ€ : homepage + recherche + page film.

            ### Initialisation
            - `_init_site()` : charge `films_ml` + `person_index`, construit le recommender
            - `_get_candidate_set(tconst_series)` : set de tconst â€œen cours / Ã  venirâ€

            ### UI / helpers
            - `render_vignettes(...)` : posters + titres
            - `homepage_ui(...)` : top genres (ranking) + priorisation candidate_set
            - `film_search_ui(...)` : recherche locale + reco KNN filtrÃ©es + fallback TMDB
            - `person_search_ui(...)` : recherche acteur + films liÃ©s (filtrÃ©s)
            - `render_site()` : tabs + page film (via `st.session_state['selected_tconst']`)

            ### Page film
            - affiche `director_name` + `cast_top` (depuis `films_ml`)
            - affiche synopsis :
            - local (`overview`) si dispo
            - sinon fallback TMDB (via `tmdb_overview_from_tconst`)

            ---

            ## 3.5 `src/market_app.py`
            **RÃ´le :** module Ã©tude de marchÃ© (INSEE/CNC) encapsulÃ©.

            - `load_market_data()` : charge les CSV marchÃ©
            - `graph_1 ... graph_9()` : graphiques
            - `render_market()` : affichage global

            ---

            # 4) `app.py` (HUB)
            **RÃ´le :** navigation principale (menu latÃ©ral) + appel des 2 apps.

            **Important :** `app.py` reste lÃ©ger et nâ€™exÃ©cute jamais les scripts offline.

            ---

            # 5) Choix du ML (Ã  prÃ©senter)

            - **Homepage** : ranking par genre (simple, stable, explicable)
            - **Recherche film** : content-based KNN (TFâ€‘IDF + cosine) â†’ similaritÃ© sur mÃ©ta-donnÃ©es
            - **Contrainte mÃ©tier** : filtrage â€œen cours / Ã  venirâ€ via TMDB (candidate_set)
            - **Fallback** : si film hors DB locale â†’ reco TMDB â€œrecommendationsâ€

            ---
            # 6) Rebuild (repo reproductible)

            1. En local :
            - `python data/imdb/traitement_db.py`
            - `python data/imdb/build_ml_ready.py`

            2. VÃ©rifier :
            - `data/imdb/out/films/part_*.csv`
            - `data/imdb/out/credits/part_*.csv`
            - `data/imdb/out/ml_ready/films_ml/part_*.csv`
            - `data/imdb/out/ml_ready/person_index.csv`

            3. Push GitHub (en parts) puis dÃ©ploiement Streamlit.io.

            """
            )

    st.info(
        """
        ## SystÃ¨me de recommandation â€” DÃ©tails Machine Learning

        Le projet repose sur un **systÃ¨me de recommandation content-based**, sans donnÃ©es utilisateurs
        (pas dâ€™historique de clics, pas de notes par utilisateur).

        Le ML est volontairement **simple, explicable et robuste**, afin dâ€™Ãªtre :
        - compatible avec un dÃ©ploiement Streamlit.io,
        - cohÃ©rent avec une base IMDb/TMDB statique.

        ---

        # 1) Pourquoi un modÃ¨le content-based (et pas collaboratif)

        Un systÃ¨me collaboratif nÃ©cessite :
        - des utilisateurs identifiÃ©s,
        - des interactions (notes, clics, historiques).

        Dans ce projet :
        - il nâ€™y a **pas dâ€™utilisateurs**,
        - pas de logs de consommation,
        - uniquement des mÃ©tadonnÃ©es films.

        ðŸ‘‰ Le **content-based filtering** est donc le seul choix pertinent.

        ---

        # 2) Architecture gÃ©nÃ©rale du ML

        Le systÃ¨me de reco est composÃ© de **2 mÃ©canismes distincts** :

        ### A) Homepage â€” Ranking (pas de ML lourd)
        - Objectif : afficher un Top films par genre
        - MÃ©thode : score calculÃ© Ã  partir de mÃ©triques existantes
        - Avantage : rapide, stable, explicable

        ### B) Recherche film / personne â€” SimilaritÃ© ML
        - Objectif : proposer des films similaires Ã  un film (ou Ã  un acteur)
        - MÃ©thode : similaritÃ© de contenu (TF-IDF + cosine)
        - Avantage : pas besoin de variable cible

        ---

        # 3) Features utilisÃ©es pour le ML (films_ml)

        Le modÃ¨le travaille sur une table **1 ligne = 1 film** (`films_ml`).

        Les features retenues sont **exclusivement textuelles et catÃ©gorielles**,
        car elles dÃ©crivent le contenu du film.

        ### Features utilisÃ©es :

        #### 1) Genres (`genres`)
        - Ex: "Comedy,Romance"
        - Feature la plus discriminante pour la similaritÃ©
        - Permet de ne jamais recommander un film hors univers

        #### 2) RÃ©alisateur (`director_name`)
        - Les films dâ€™un mÃªme rÃ©alisateur partagent souvent un style
        - TrÃ¨s pertinent pour la recommandation qualitative

        #### 3) Casting principal (`cast_top`)
        - Top acteurs/actrices (2 Ã  5 max)
        - Important pour la recherche â€œpar acteurâ€
        - Ajoute une dimension shÃ©ma en Ã©toile

        #### 4) Titres (`primaryTitle`, `originalTitle`)
        - Permet de rapprocher des sagas, remakes, suites
        - AmÃ©liore la cohÃ©rence sÃ©mantique

        ---

        # 4) Construction de la feature ML principale : la "soup"

        Toutes les features sont combinÃ©es dans une **feature texte unique** appelÃ©e `soup`.

        Exemple simplifiÃ© :

            soup = "
                Kate & Leopold
                Comedy Romance Fantasy
                James Mangold
                Meg Ryan Hugh Jackman
            "

        Pourquoi cette approche ?
        - TF-IDF fonctionne trÃ¨s bien sur du texte libre
        - Pas besoin de normaliser chaque feature sÃ©parÃ©ment
        - MÃ©thode classique utilisÃ©e dans de nombreux systÃ¨mes de reco simples

        ---

        # 5) ModÃ¨le utilisÃ© : TF-IDF + SimilaritÃ© Cosine

        ### Ã‰tape 1 â€” Vectorisation (TF-IDF)
        - Chaque film est transformÃ© en vecteur numÃ©rique
        - Les mots rares sont plus importants que les mots frÃ©quents
        - Aucun apprentissage supervisÃ©

        ### Ã‰tape 2 â€” SimilaritÃ© Cosine
        - Mesure lâ€™angle entre deux vecteurs films
        - Plus lâ€™angle est faible â†’ films similaires
        - RÃ©sultat : un score de similaritÃ© âˆˆ [0,1]

        ### Ã‰tape 3 â€” KNN implicite
        - Pour un film donnÃ© :
        - on calcule la similaritÃ© avec tous les autres films
        - on prend les **Top N voisins**
        - Pas besoin dâ€™un `KNeighborsClassifier` classique
        - Plus rapide et plus contrÃ´lable

        ---

        # 6) Recherche par film

        Workflow :
        1. Lâ€™utilisateur sÃ©lectionne un film
        2. On rÃ©cupÃ¨re son `tconst`
        3. On calcule les similaritÃ©s avec tous les films
        4. On retourne les films les plus proches
        5. On applique un **filtre mÃ©tier** (voir section suivante)

        ---

        # 7) Recherche par personne (acteur / rÃ©alisateur)

        Workflow :
        1. Recherche du nom dans `person_index`
        2. RÃ©cupÃ©ration des films liÃ©s Ã  cette personne
        3. Union des recommandations ML de ces films
        4. Suppression des doublons
        5. Filtrage mÃ©tier

        Cela permet :
        - une recherche â€œacteurâ€ sans modÃ¨le spÃ©cifique
        - de rester cohÃ©rent avec le mÃªme moteur ML

        ---

        # 8) Filtrage mÃ©tier : films Â« en cours / Ã  venir Â»

        Le modÃ¨le ML calcule la similaritÃ© **sur toute la base**,
        mais lâ€™affichage final applique une contrainte mÃ©tier forte :

        ðŸ‘‰ **ne recommander que des films en salle ou Ã  venir**.

        Cette contrainte est implÃ©mentÃ©e via :
        - appels TMDB (`now_playing`, `upcoming`)
        - conversion TMDB â†’ IMDb (`imdb_id`)
        - crÃ©ation dâ€™un `candidate_set` (ensemble de tconst autorisÃ©s)

        Le ML **ne change pas** :
        - on filtre simplement les rÃ©sultats finaux.

        Avantage :
        - sÃ©paration claire ML / rÃ¨gles mÃ©tier
        - modÃ¨le stable et rÃ©utilisable

        ---

        # 9) Pourquoi ce choix est pertinent pour un projet Data Analyst

        - ModÃ¨le explicable (pas de boÃ®te noire)
        - Pas de sur-ingÃ©nierie
        - Performant sur 100k films
        - DÃ©ployable sur Streamlit.io
        - AlignÃ© avec une Ã©tude de marchÃ© (logique mÃ©tier)

        Ce systÃ¨me est volontairement **simple mais solide** :
        il montre la maÃ®trise du pipeline data, du feature engineering,
        et de lâ€™intÃ©gration ML dans une application rÃ©elle.
        """
        )